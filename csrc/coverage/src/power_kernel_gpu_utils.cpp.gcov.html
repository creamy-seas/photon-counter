<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - üêã Test Coverage - src/power_kernel_gpu_utils.cpp</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">src</a> - power_kernel_gpu_utils.cpp<span style="font-size: 80%;"> (source / <a href="power_kernel_gpu_utils.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">üêã Test Coverage</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">49</td>
            <td class="headerCovTableEntry">91</td>
            <td class="headerCovTableEntryLo">53.8 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-05-20 19:29:47</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">5</td>
            <td class="headerCovTableEntry">7</td>
            <td class="headerCovTableEntryLo">71.4 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /*</a>
<span class="lineNum">       2 </span>            :  * Everything that can be compiled without the nvcc for the GPU power kernel
<span class="lineNum">       3 </span>            :  * - Allocating data on device
<span class="lineNum">       4 </span>            :  * - Fetching kernel parameters
<span class="lineNum">       5 </span>            :  */
<span class="lineNum">       6 </span>            : 
<span class="lineNum">       7 </span>            : #include &lt;cuda_runtime.h&gt; // cudaMalloc cudaFree
<span class="lineNum">       8 </span>            : #include &lt;cuda_runtime_api.h&gt; //for cudaDeviceProp
<span class="lineNum">       9 </span>            : 
<span class="lineNum">      10 </span>            : #include &lt;string&gt;
<span class="lineNum">      11 </span>            : #include &quot;colours.hpp&quot; // RED, OKBLUE etc
<span class="lineNum">      12 </span>            : #include &quot;power_kernel.hpp&quot; // for power kernel parameters
<span class="lineNum">      13 </span>            : #include &quot;ia_ADQAPI.hpp&quot; // for digitiser parameters MAX_CODE and MAX_NUMBER_OF_RECORDS
<a name="14"><span class="lineNum">      14 </span>            : #include &quot;utils_gpu.hpp&quot; // To fetch GPU parameters</a>
<span class="lineNum">      15 </span>            : 
<span class="lineNum">      16 </span><span class="lineCov">          1 : GPU::PowerKernelParameters::PowerKernelParameters(</span>
<span class="lineNum">      17 </span>            :     int r_points,
<span class="lineNum">      18 </span>            :     int np_points,
<span class="lineNum">      19 </span>            :     int blocks,
<span class="lineNum">      20 </span>            :     int threads_per_block
<span class="lineNum">      21 </span>            :     ){
<span class="lineNum">      22 </span><span class="lineCov">          1 :     this-&gt;r_points = r_points;</span>
<span class="lineNum">      23 </span><span class="lineCov">          1 :     this-&gt;np_points = np_points;</span>
<span class="lineNum">      24 </span><span class="lineCov">          1 :     this-&gt;blocks = blocks;</span>
<span class="lineNum">      25 </span><span class="lineCov">          1 :     this-&gt;threads_per_block = threads_per_block;</span>
<span class="lineNum">      26 </span>            : 
<span class="lineNum">      27 </span><span class="lineCov">          1 :     this-&gt;print();</span>
<a name="28"><span class="lineNum">      28 </span><span class="lineCov">          1 : }</span></a>
<span class="lineNum">      29 </span>            : 
<span class="lineNum">      30 </span><span class="lineCov">          1 : void GPU::PowerKernelParameters::print(){</span>
<span class="lineNum">      31 </span><span class="lineCov">          1 :     OKBLUE(&quot;===========================================&quot;);</span>
<span class="lineNum">      32 </span><span class="lineCov">          1 :     RED(&quot;          **POWER KERNEL**&quot;);</span>
<span class="lineNum">      33 </span>            : 
<span class="lineNum">      34 </span><span class="lineCov">          1 :     OKBLUE(&quot;Data Parameters&quot;);</span>
<span class="lineNum">      35 </span><span class="lineCov">          1 :     WHITE(&quot;R_POINTS: %i\n&quot;, this-&gt;r_points );</span>
<span class="lineNum">      36 </span><span class="lineCov">          1 :     WHITE(&quot;SP_POINTS: %i\n&quot;, this-&gt;np_points );</span>
<span class="lineNum">      37 </span>            : 
<span class="lineNum">      38 </span><span class="lineCov">          1 :     OKBLUE(&quot;Processing Parameters&quot;);</span>
<span class="lineNum">      39 </span><span class="lineCov">          1 :     WHITE(&quot;BLOCKS: %i\n&quot;, this-&gt;blocks );</span>
<span class="lineNum">      40 </span><span class="lineCov">          1 :     WHITE(&quot;THREADS_PER_BLOCK: %i\n&quot;, this-&gt;threads_per_block );</span>
<span class="lineNum">      41 </span>            : 
<span class="lineNum">      42 </span><span class="lineCov">          1 :     OKBLUE(&quot;===========================================&quot;);</span>
<a name="43"><span class="lineNum">      43 </span><span class="lineCov">          1 : }</span></a>
<span class="lineNum">      44 </span>            : 
<span class="lineNum">      45 </span><span class="lineCov">          1 : GPU::PowerKernelParameters GPU::fetch_kernel_parameters(){</span>
<span class="lineNum">      46 </span>            :     // Even number required for summation on GPU
<span class="lineNum">      47 </span>            :     if (R_POINTS % 2 != 0)
<span class="lineNum">      48 </span>            :         throw std::runtime_error(
<span class="lineNum">      49 </span>            :             &quot;R_POINTS=&quot;
<span class="lineNum">      50 </span>            :             + std::to_string(R_POINTS)
<span class="lineNum">      51 </span>            :             + &quot; needs to be a even number.&quot;);
<span class="lineNum">      52 </span>            : 
<span class="lineNum">      53 </span>            :     // Check that &quot;chunking&quot; falls within the limits of shared memory on GPU
<span class="lineNum">      54 </span><span class="lineCov">          1 :     cudaDeviceProp prop = fetch_gpu_parameters();</span>
<span class="lineNum">      55 </span><span class="lineCov">          1 :     int sizeof_unsigned_int = 4;</span>
<span class="lineNum">      56 </span><span class="lineCov">          1 :     int number_of_cumulative_arrays = 4;</span>
<span class="lineNum">      57 </span>            :     int shared_memory_required = (R_POINTS_CHUNK
<span class="lineNum">      58 </span><span class="lineCov">          1 :                                   * sizeof_unsigned_int</span>
<span class="lineNum">      59 </span><span class="lineCov">          1 :                                   * number_of_cumulative_arrays);</span>
<span class="lineNum">      60 </span><span class="lineCov">          1 :     if (prop.sharedMemPerBlock &lt; shared_memory_required)</span>
<span class="lineNum">      61 </span>            :         throw std::runtime_error(
<span class="lineNum">      62 </span>            :             &quot;Not enough shared memory on GPU (&quot;
<span class="lineNum">      63 </span><span class="lineNoCov">          0 :             + std::to_string(shared_memory_required)</span>
<span class="lineNum">      64 </span><span class="lineNoCov">          0 :             + &quot; &gt; &quot;</span>
<span class="lineNum">      65 </span><span class="lineNoCov">          0 :             + std::to_string(prop.sharedMemPerBlock)</span>
<span class="lineNum">      66 </span><span class="lineNoCov">          0 :             + &quot; bytes) for using R_POINTS_CHUNK=&quot;</span>
<span class="lineNum">      67 </span><span class="lineNoCov">          0 :             + std::to_string(R_POINTS_CHUNK)</span>
<span class="lineNum">      68 </span><span class="lineNoCov">          0 :             + &quot; in power mesurements.&quot;</span>
<span class="lineNum">      69 </span><span class="lineNoCov">          0 :             );</span>
<span class="lineNum">      70 </span>            : 
<span class="lineNum">      71 </span>            :     // Check that chunking of R_POINTS is valid
<span class="lineNum">      72 </span>            :     if (R_POINTS &lt; R_POINTS_CHUNK)
<span class="lineNum">      73 </span>            :         throw std::runtime_error(
<span class="lineNum">      74 </span>            :             &quot;R_POINTS (&quot;
<span class="lineNum">      75 </span>            :             + std::to_string(R_POINTS)
<span class="lineNum">      76 </span>            :             + &quot;) &lt; R_POINTS_CHUNK (&quot;
<span class="lineNum">      77 </span>            :             + std::to_string(R_POINTS_CHUNK)
<span class="lineNum">      78 </span>            :             + &quot;): Chunking is bigger than amount of repititions on digitiser.&quot;
<span class="lineNum">      79 </span>            :             );
<span class="lineNum">      80 </span>            :     if ((R_POINTS - (R_POINTS / R_POINTS_CHUNK) * R_POINTS_CHUNK) != 0)
<span class="lineNum">      81 </span>            :         throw std::runtime_error(
<span class="lineNum">      82 </span>            :             &quot;R_POINTS_CHUNK (&quot;
<span class="lineNum">      83 </span>            :             + std::to_string(R_POINTS_CHUNK)
<span class="lineNum">      84 </span>            :             + &quot;) does not fit fully into R_POINTS (&quot;
<span class="lineNum">      85 </span>            :             + std::to_string(R_POINTS)
<span class="lineNum">      86 </span>            :             + &quot;).&quot;);
<span class="lineNum">      87 </span>            :     if ((R_POINTS / R_POINTS_CHUNK % 2) != 0)
<span class="lineNum">      88 </span>            :             throw std::runtime_error(
<span class="lineNum">      89 </span>            :                 &quot;R_POINTS_CHUNK (&quot;
<span class="lineNum">      90 </span>            :                 + std::to_string(R_POINTS_CHUNK)
<span class="lineNum">      91 </span>            :                 + &quot;) does not chunk R_POINTS (&quot;
<span class="lineNum">      92 </span>            :                 + std::to_string(R_POINTS)
<span class="lineNum">      93 </span>            :                 + &quot;) evenly across the 2 streams.&quot;);
<span class="lineNum">      94 </span>            : 
<span class="lineNum">      95 </span>            :     // Ensure that the cumulative arrays will not overflow.
<span class="lineNum">      96 </span><span class="lineCov">          1 :     unsigned long int max = -1UL;</span>
<span class="lineNum">      97 </span><span class="lineCov">          1 :     if ((MAX_CODE * MAX_NUMBER_OF_RECORDS &gt; max) ||</span>
<span class="lineNum">      98 </span><span class="lineCov">          1 :         (MAX_CODE * MAX_CODE * MAX_NUMBER_OF_RECORDS &gt; max) ||</span>
<span class="lineNum">      99 </span>            :         (2 * MAX_CODE * MAX_CODE * MAX_NUMBER_OF_RECORDS &gt; max))
<span class="lineNum">     100 </span>            :         throw std::runtime_error(
<span class="lineNum">     101 </span><span class="lineNoCov">          0 :             &quot;Cumulative arrays will not be able to hold all the intermediate processing data for power measurements&quot;);</span>
<span class="lineNum">     102 </span>            : 
<span class="lineNum">     103 </span>            :     // Reset is checked in python
<span class="lineNum">     104 </span>            :     return GPU::PowerKernelParameters(
<span class="lineNum">     105 </span>            :         R_POINTS,
<span class="lineNum">     106 </span>            :         SP_POINTS,
<span class="lineNum">     107 </span>            :         BLOCKS,
<span class="lineNum">     108 </span>            :         THREADS_PER_BLOCK
<span class="lineNum">     109 </span><span class="lineCov">          1 :         );</span>
<a name="110"><span class="lineNum">     110 </span>            : }</a>
<span class="lineNum">     111 </span>            : 
<span class="lineNum">     112 </span><span class="lineCov">          4 : void GPU::V1::allocate_memory(short ***gpu_in, double ***gpu_out){</span>
<span class="lineNum">     113 </span>            :     // Pass in ADDRESS of pointers (&amp;POINTER) -&gt; this will allocate memory on GPU
<span class="lineNum">     114 </span><span class="lineCov">          4 :     int success = 0;</span>
<span class="lineNum">     115 </span><span class="lineCov">          4 :     OKBLUE(&quot;Power Kernel: Allocating memory on GPU and CPU.&quot;);</span>
<span class="lineNum">     116 </span>            : 
<span class="lineNum">     117 </span>            :     // Input data is fed in chunks of R_POINTS_CHUNK * SP_POINTS
<span class="lineNum">     118 </span><span class="lineCov">          4 :     success += cudaMalloc((void**)gpu_in[CHA], SP_POINTS * R_POINTS * sizeof(short));</span>
<span class="lineNum">     119 </span><span class="lineCov">          4 :     success += cudaMalloc((void**)gpu_in[CHB], SP_POINTS * R_POINTS * sizeof(short));</span>
<span class="lineNum">     120 </span>            : 
<span class="lineNum">     121 </span>            :     // Output data is read out from GPU and stored in persistent memory on CPU
<span class="lineNum">     122 </span><span class="lineCov">         20 :     for (int i(0); i &lt; GPU::no_outputs_from_gpu; i++)</span>
<span class="lineNum">     123 </span><span class="lineCov">         16 :         success += cudaMalloc((void**)gpu_out[GPU::outputs_from_gpu[i]], SP_POINTS * sizeof(double));</span>
<span class="lineNum">     124 </span><span class="lineCov">          4 :     if (success != 0) FAIL(&quot;Power Kernel: Failed to allocate memory on GPU.&quot;);</span>
<span class="lineNum">     125 </span>            : 
<span class="lineNum">     126 </span><span class="lineCov">          4 :     OKGREEN(&quot;Power Kernel: Allocation done!&quot;);</span>
<a name="127"><span class="lineNum">     127 </span><span class="lineCov">          4 : }</span></a>
<span class="lineNum">     128 </span>            : 
<span class="lineNum">     129 </span><span class="lineCov">          4 : void GPU::V1::free_memory(short ***gpu_in, double ***gpu_out){</span>
<span class="lineNum">     130 </span>            :     // Call to deallocated memory on GPU after run is complete
<span class="lineNum">     131 </span><span class="lineCov">          4 :     int success = 0;</span>
<span class="lineNum">     132 </span><span class="lineCov">          4 :     OKBLUE(&quot;Power Kernel: Deallocating memory on GPU.&quot;);</span>
<span class="lineNum">     133 </span><span class="lineCov">          4 :     success += cudaFree(*gpu_in[CHA]);</span>
<span class="lineNum">     134 </span><span class="lineCov">          4 :     success += cudaFree(*gpu_in[CHB]);</span>
<span class="lineNum">     135 </span>            : 
<span class="lineNum">     136 </span><span class="lineCov">         20 :     for (int i(0); i &lt; GPU::no_outputs_from_gpu; i++) {</span>
<span class="lineNum">     137 </span><span class="lineCov">         16 :         success += cudaFree(*gpu_out[GPU::outputs_from_gpu[i]]);</span>
<span class="lineNum">     138 </span>            :     }
<span class="lineNum">     139 </span><span class="lineCov">          4 :     if (success != 0) FAIL(&quot;Power Kernel: Failed to free  memory on GPU.&quot;);</span>
<span class="lineNum">     140 </span>            : 
<span class="lineNum">     141 </span><span class="lineCov">          4 :     OKGREEN(&quot;Power Kernel: Memory freed!&quot;);</span>
<a name="142"><span class="lineNum">     142 </span><span class="lineCov">          4 : }</span></a>
<span class="lineNum">     143 </span>            : 
<span class="lineNum">     144 </span><span class="lineNoCov">          0 : void GPU::V2::allocate_memory(</span>
<span class="lineNum">     145 </span>            :     short ***gpu_in0,
<span class="lineNum">     146 </span>            :     short ***gpu_in1,
<span class="lineNum">     147 </span>            :     double ***gpu_out0,
<span class="lineNum">     148 </span>            :     double ***gpu_out1,
<span class="lineNum">     149 </span>            :     double ***cpu_out0,
<span class="lineNum">     150 </span>            :     double ***cpu_out1
<span class="lineNum">     151 </span>            :     ){
<span class="lineNum">     152 </span><span class="lineNoCov">          0 :     int success = 0;</span>
<span class="lineNum">     153 </span>            : 
<span class="lineNum">     154 </span><span class="lineNoCov">          0 :     OKBLUE(&quot;Power Kernel: Allocating memory on GPU and CPU.&quot;);</span>
<span class="lineNum">     155 </span>            : 
<span class="lineNum">     156 </span>            :     // Input data is fed in chunks of R_POINTS_CHUNK * SP_POINTS
<span class="lineNum">     157 </span><span class="lineNoCov">          0 :     success += cudaMalloc((void**)gpu_in0[CHA], SP_POINTS * R_POINTS_CHUNK * sizeof(short));</span>
<span class="lineNum">     158 </span><span class="lineNoCov">          0 :     success += cudaMalloc((void**)gpu_in0[CHB], SP_POINTS * R_POINTS_CHUNK * sizeof(short));</span>
<span class="lineNum">     159 </span><span class="lineNoCov">          0 :     success += cudaMalloc((void**)gpu_in1[CHA], SP_POINTS * R_POINTS_CHUNK * sizeof(short));</span>
<span class="lineNum">     160 </span><span class="lineNoCov">          0 :     success += cudaMalloc((void**)gpu_in1[CHB], SP_POINTS * R_POINTS_CHUNK * sizeof(short));</span>
<span class="lineNum">     161 </span>            : 
<span class="lineNum">     162 </span>            :     // Output data is read out from GPU and stored in persistent memory on CPU
<span class="lineNum">     163 </span><span class="lineNoCov">          0 :     for (int i(0); i &lt; GPU::no_outputs_from_gpu; i++) {</span>
<span class="lineNum">     164 </span><span class="lineNoCov">          0 :         success += cudaMalloc((void**)gpu_out0[GPU::outputs_from_gpu[i]], SP_POINTS * sizeof(double));</span>
<span class="lineNum">     165 </span><span class="lineNoCov">          0 :         success += cudaMalloc((void**)gpu_out1[GPU::outputs_from_gpu[i]], SP_POINTS * sizeof(double));</span>
<span class="lineNum">     166 </span><span class="lineNoCov">          0 :         if (success != 0) FAIL(&quot;Power Kernel: Failed to allocate memory on GPU.&quot;);</span>
<span class="lineNum">     167 </span>            : 
<span class="lineNum">     168 </span><span class="lineNoCov">          0 :         success += cudaHostAlloc((void**)cpu_out0[GPU::outputs_from_gpu[i]],</span>
<span class="lineNum">     169 </span>            :                                  SP_POINTS * R_POINTS/R_POINTS_CHUNK * sizeof(double),
<span class="lineNum">     170 </span><span class="lineNoCov">          0 :                                  cudaHostAllocDefault);</span>
<span class="lineNum">     171 </span><span class="lineNoCov">          0 :         success += cudaHostAlloc((void**)cpu_out1[GPU::outputs_from_gpu[i]],</span>
<span class="lineNum">     172 </span>            :                                  SP_POINTS * R_POINTS/R_POINTS_CHUNK * sizeof(double),
<span class="lineNum">     173 </span><span class="lineNoCov">          0 :                                  cudaHostAllocDefault);</span>
<span class="lineNum">     174 </span><span class="lineNoCov">          0 :         if (success != 0) FAIL(&quot;Power Kernel: Failed to allocate memory on CPU.&quot;);</span>
<span class="lineNum">     175 </span>            :     }
<span class="lineNum">     176 </span>            : 
<span class="lineNum">     177 </span><span class="lineNoCov">          0 :     OKGREEN(&quot;Power Kernel: Allocation done!&quot;);</span>
<a name="178"><span class="lineNum">     178 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     179 </span>            : 
<span class="lineNum">     180 </span><span class="lineNoCov">          0 : void GPU::V2::free_memory(</span>
<span class="lineNum">     181 </span>            :     short ***gpu_in0, short ***gpu_in1,
<span class="lineNum">     182 </span>            :     double ***gpu_out0, double ***gpu_out1,
<span class="lineNum">     183 </span>            :     double ***cpu_out0, double ***cpu_out1){
<span class="lineNum">     184 </span><span class="lineNoCov">          0 :     int success = 0;</span>
<span class="lineNum">     185 </span>            : 
<span class="lineNum">     186 </span><span class="lineNoCov">          0 :     OKBLUE(&quot;Power Kernel: Deallocating memory on GPU.&quot;);</span>
<span class="lineNum">     187 </span><span class="lineNoCov">          0 :     success += cudaFree(*gpu_in0[CHA]);</span>
<span class="lineNum">     188 </span><span class="lineNoCov">          0 :     success += cudaFree(*gpu_in0[CHB]);</span>
<span class="lineNum">     189 </span><span class="lineNoCov">          0 :     success += cudaFree(*gpu_in1[CHA]);</span>
<span class="lineNum">     190 </span><span class="lineNoCov">          0 :     success += cudaFree(*gpu_in1[CHB]);</span>
<span class="lineNum">     191 </span>            : 
<span class="lineNum">     192 </span><span class="lineNoCov">          0 :     for (int i(0); i &lt; GPU::no_outputs_from_gpu; i++) {</span>
<span class="lineNum">     193 </span><span class="lineNoCov">          0 :         success += cudaFree(*gpu_out0[GPU::outputs_from_gpu[i]]);</span>
<span class="lineNum">     194 </span><span class="lineNoCov">          0 :         success += cudaFree(*gpu_out1[GPU::outputs_from_gpu[i]]);</span>
<span class="lineNum">     195 </span><span class="lineNoCov">          0 :         if (success != 0) FAIL(&quot;Power Kernel: Failed to free  memory on GPU.&quot;);</span>
<span class="lineNum">     196 </span>            : 
<span class="lineNum">     197 </span><span class="lineNoCov">          0 :         success += cudaFreeHost(*cpu_out0[GPU::outputs_from_gpu[i]]);</span>
<span class="lineNum">     198 </span><span class="lineNoCov">          0 :         success += cudaFreeHost(*cpu_out1[GPU::outputs_from_gpu[i]]);</span>
<span class="lineNum">     199 </span><span class="lineNoCov">          0 :         if (success != 0) FAIL(&quot;Power Kernel: Failed to free memory on CPU.&quot;);</span>
<span class="lineNum">     200 </span>            :     }
<span class="lineNum">     201 </span>            : 
<span class="lineNum">     202 </span><span class="lineNoCov">          0 :     OKGREEN(&quot;Power Kernel: Memory freed!&quot;);</span>
<span class="lineNum">     203 </span><span class="lineNoCov">          0 : }</span>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
